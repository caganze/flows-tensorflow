#!/bin/bash

# üß† Smart Regular Flow Batch Submission (50 Array Limit)
# Groups remaining particles into 50 batches and runs them in for loops

set -e

# Activate bosque conda environment
source ~/.bashrc
conda activate bosque

echo "üß† SMART REGULAR FLOW BATCH SUBMISSION (50 ARRAY LIMIT)"
echo "======================================================"
echo "üîç Filters completed particles and groups into 50 batches"
echo "üìÅ Output: /oak/stanford/orgs/kipac/users/caganze/flows-tensorflow/tfp_output/"
echo ""

# Default parameters
MAX_ARRAYS=50
PARTITION="owners"
PARTICLE_LIST_FILE="particle_list.txt"
DRY_RUN=false
VERBOSE=false

show_usage() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "OPTIONS:"
    echo "  --max-arrays N      Maximum array jobs (default: 50)"
    echo "  --partition NAME    SLURM partition (default: owners)"
    echo "  --particle-list FILE Particle list file (default: particle_list.txt)"
    echo "  --verbose           Show detailed filtering progress"
    echo "  --dry-run           Show what would be submitted without submitting"
    echo "  --help              Show this help"
    echo ""
    echo "PROCESS:"
    echo "  1. Filters completed regular flow particles"
    echo "  2. Groups remaining particles into 50 batches"
    echo "  3. Each batch runs particles in for loop (no array limit hit)"
    echo "  4. 12 hour time limit per batch, GPU processing"
    echo ""
}

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --max-arrays)
            MAX_ARRAYS="$2"
            shift 2
            ;;
        --partition)
            PARTITION="$2"
            shift 2
            ;;
        --particle-list)
            PARTICLE_LIST_FILE="$2"
            shift 2
            ;;
        --verbose)
            VERBOSE=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --help)
            show_usage
            exit 0
            ;;
        *)
            echo "‚ùå Unknown option: $1"
            show_usage
            exit 1
            ;;
    esac
done

# Check required files
required_files=(
    "regular_batch_job.sh"
    "filter_completed_particles.sh"
)

for file in "${required_files[@]}"; do
    if [[ ! -f "$file" ]]; then
        echo "‚ùå Required file missing: $file"
        echo "üí° Creating missing files..."
        exit 1
    fi
done

echo "‚úÖ All required files found"

# Step 1: Filter completed particles
echo ""
echo "üîç STEP 1: Filtering completed regular flow particles"
echo "=================================================="

FILTER_ARGS=""
if [[ "$VERBOSE" == "true" ]]; then
    FILTER_ARGS="--verbose"
fi

if [[ "$DRY_RUN" == "true" ]]; then
    FILTER_ARGS="$FILTER_ARGS --dry-run"
fi

if ! ./filter_completed_particles.sh --input "$PARTICLE_LIST_FILE" $FILTER_ARGS; then
    echo "‚ùå Failed to filter particles"
    exit 1
fi

# Check if we have any incomplete particles (only if not dry run)
if [[ "$DRY_RUN" != "true" ]]; then
    if [[ ! -f "particle_list_incomplete.txt" || ! -s "particle_list_incomplete.txt" ]]; then
        echo ""
        echo "üéâ ALL REGULAR FLOW PARTICLES COMPLETED!"
        echo "======================================="
        echo "‚úÖ No incomplete particles found - all regular flow work is done!"
        exit 0
    fi
    
    INCOMPLETE_COUNT=$(wc -l < particle_list_incomplete.txt)
    echo ""
    echo "üìä Found $INCOMPLETE_COUNT incomplete regular flow particles to process"
else
    # For dry run, estimate from filter output
    INCOMPLETE_COUNT=$(grep "Would contain" <<< "$(./filter_completed_particles.sh --dry-run 2>/dev/null)" | grep -o '[0-9]\+' || echo "460")
    echo ""
    echo "üìä Estimated $INCOMPLETE_COUNT incomplete particles (dry run)"
fi

# Step 2: Create batches
echo ""
echo "üöÄ STEP 2: Creating batches for submission"
echo "=========================================="

PARTICLES_PER_BATCH=$(( (INCOMPLETE_COUNT + MAX_ARRAYS - 1) / MAX_ARRAYS ))
echo "üìä Grouping $INCOMPLETE_COUNT particles into $MAX_ARRAYS batches"
echo "üì¶ ~$PARTICLES_PER_BATCH particles per batch"

echo ""
echo "üìã REGULAR FLOW BATCH SUBMISSION PLAN"
echo "===================================="
echo "üéØ Max arrays: $MAX_ARRAYS"
echo "üì¶ Particles per batch: ~$PARTICLES_PER_BATCH"
echo "‚è∞ Time per batch: 12:00:00"
echo "üíæ Memory per batch: 128GB"
echo "üéÆ GPUs per batch: 1"
echo "üìÅ Output: /oak/stanford/orgs/kipac/users/caganze/flows-tensorflow/tfp_output/"
echo ""

if [[ "$DRY_RUN" == "true" ]]; then
    echo "üß™ DRY RUN - Commands that would be executed:"
    echo ""
    
    for (( batch=1; batch<=MAX_ARRAYS; batch++ )); do
        start_line=$(( (batch - 1) * PARTICLES_PER_BATCH + 1 ))
        end_line=$(( batch * PARTICLES_PER_BATCH ))
        
        if [[ $start_line -le $INCOMPLETE_COUNT ]]; then
            if [[ $end_line -gt $INCOMPLETE_COUNT ]]; then
                end_line=$INCOMPLETE_COUNT
            fi
            
            actual_particles=$((end_line - start_line + 1))
            echo "üì¶ Batch $batch: lines $start_line-$end_line ($actual_particles particles)"
            echo "  sbatch --job-name=regular_batch_$batch --time=12:00:00 --mem=128GB --gres=gpu:1 --partition=$PARTITION regular_batch_job.sh $start_line $end_line"
        fi
    done
    
    echo ""
    echo "‚úÖ Dry run completed - no jobs submitted"
    echo "üí° Run without --dry-run to actually submit"
else
    # Step 3: Submit batches
    echo "üöÄ STEP 3: Submitting regular flow batches"
    echo "========================================="
    
    SUBMITTED_JOBS=()
    
    for (( batch=1; batch<=MAX_ARRAYS; batch++ )); do
        start_line=$(( (batch - 1) * PARTICLES_PER_BATCH + 1 ))
        end_line=$(( batch * PARTICLES_PER_BATCH ))
        
        if [[ $start_line -le $INCOMPLETE_COUNT ]]; then
            if [[ $end_line -gt $INCOMPLETE_COUNT ]]; then
                end_line=$INCOMPLETE_COUNT
            fi
            
            actual_particles=$((end_line - start_line + 1))
            echo "üì¶ Submitting Batch $batch: lines $start_line-$end_line ($actual_particles particles)"
            
            JOB_ID=$(sbatch \
                --job-name="regular_batch_$batch" \
                --time=12:00:00 \
                --mem=128GB \
                --gres=gpu:1 \
                --partition=$PARTITION \
                --output="logs/regular_batch_%j.out" \
                --error="logs/regular_batch_%j.err" \
                regular_batch_job.sh $start_line $end_line | grep -o '[0-9]\+')
            
            if [[ -n "$JOB_ID" ]]; then
                echo "  ‚úÖ Submitted: Job ID $JOB_ID"
                SUBMITTED_JOBS+=("$JOB_ID")
            else
                echo "  ‚ùå Failed to submit batch $batch"
            fi
            
            # Brief pause between submissions
            sleep 1
        fi
    done
    
    echo ""
    echo "üéâ REGULAR FLOW BATCH SUBMISSION COMPLETED"
    echo "========================================="
    echo "üì¶ Submitted batches: $((${#SUBMITTED_JOBS[@]}))"
    echo "üÜî Job IDs: ${SUBMITTED_JOBS[*]}"
    echo ""
    echo "üìä Monitor progress:"
    echo "   ./monitor_brute_force.sh --follow"
    echo ""
    echo "üîç Check job status:"
    echo "   squeue -u \$USER"
fi

echo ""
echo "üí° Each batch will process particles sequentially in a for loop"
echo "üéØ No array job limits hit - stays within 50 job limit"


