# üéÆ GPU Array Job Fixes Summary

## üîß **PROBLEMS FIXED**

### 1. **Array Job Logic Fixed**
- ‚ùå **Old**: Used hardcoded file discovery + random PIDs (718, 800, 852)
- ‚úÖ **New**: Uses `particle_list.txt` with proper array indexing

### 2. **QOS Limit Protection**
- ‚ùå **Old**: Would submit 22,713 tasks at once ‚Üí QOS limit crash
- ‚úÖ **New**: Smart chunking system filters completed particles first

### 3. **Completed Particle Filtering**
- ‚ùå **Old**: No filtering before submission
- ‚úÖ **New**: Automatically skips particles with existing `.npz` files

## üöÄ **NEW SCRIPTS CREATED**

### **Smart GPU Submission** (`submit_gpu_smart.sh`)
- Filters completed particles automatically
- Submits only incomplete particles in safe chunks
- Default: 200 particles/chunk, 3 concurrent

### **GPU Chunked Submission** (`submit_gpu_chunked.sh`)
- Manual chunking for large particle lists
- Flexible chunk sizes and concurrency limits
- Can resume from specific chunks

### **GPU Monitoring** (`monitor_brute_force.sh`)
- Real-time job monitoring
- Success/failure tracking
- Resource usage monitoring

## üìã **USAGE GUIDE**

### **Recommended Workflow:**
1. **Cancel broken jobs:**
   ```bash
   scancel 5064866 5064867 5026590
   ```

2. **Upload fixed scripts:**
   ```bash
   ./rsync_to_sherlock.sh
   ```

3. **Submit smartly:**
   ```bash
   # RECOMMENDED: Automatic filtering + chunking
   ./submit_gpu_smart.sh
   
   # OR manual chunking
   ./submit_gpu_chunked.sh --chunk-size 200 --concurrent 3
   
   # OR test first
   ./submit_gpu_smart.sh --dry-run
   ```

4. **Monitor progress:**
   ```bash
   ./monitor_brute_force.sh --follow
   ```

## ‚úÖ **WHAT'S FIXED IN brute_force_gpu_job.sh**

### **Before:**
```bash
# Found hardcoded PIDs and files
PIDS=(1 2 3 4 5 23 88 188 268 327 364 415 440 469 530 570 641 718 800 852 939)
SELECTED_PID="${PIDS[$PID_INDEX]}"  # Wrong indexing
```

### **After:**
```bash
# Uses particle list
PARTICLE_LINE=$(sed -n "${ARRAY_ID}p" "$PARTICLE_LIST_FILE")
IFS=',' read -r SELECTED_PID SELECTED_FILE PARTICLE_COUNT SIZE_CLASS <<< "$PARTICLE_LINE"
```

## üéØ **EXPECTED RESULTS**

### **New Log Output:**
```
üöÄ BRUTE FORCE GPU JOB - ARRAY TASK 39
üîß Mode: Particle List Processing
üìã Using particle list: particle_list.txt
üéØ Processing: PID 39 from eden_scaled_Halo268_sunrot0_0kpc200kpcoriginal_particles.h5
   Objects: 8156 (Small)
‚úÖ Successfully trained model for PID 39
```

### **Success Indicators:**
- ‚úÖ Correct PID-to-file mapping
- ‚úÖ No "No particles found" errors
- ‚úÖ Multiple `.npz` files created
- ‚úÖ Kroupa IMF sampling working
- ‚úÖ Jobs stay under QOS limits

## üîç **VERIFICATION COMMANDS**

### **Check job status:**
```bash
squeue --me
```

### **Monitor in real-time:**
```bash
./monitor_brute_force.sh --follow
```

### **Download and check logs:**
```bash
./download_sherlock_logs.sh
grep "Processing.*PID" sherlock_logs/brute_force_*.out
```

### **Verify no errors:**
```bash
grep -i "no particles found\|error\|failed" sherlock_logs/brute_force_*.out
```

## üí° **KEY IMPROVEMENTS**

1. **Prevents QOS crashes** with smart chunking
2. **Avoids reprocessing** completed particles  
3. **Uses correct PID mapping** from particle list
4. **Provides real-time monitoring** and progress tracking
5. **Enables easy resubmission** of failed chunks

## üéâ **BOTTOM LINE**

Your GPU array jobs will now:
- ‚úÖ Process the correct particles
- ‚úÖ Stay within QOS limits
- ‚úÖ Skip completed work
- ‚úÖ Use Kroupa IMF properly
- ‚úÖ Generate multiple `.npz` files successfully

**No more "only one file" issues!** üöÄ

