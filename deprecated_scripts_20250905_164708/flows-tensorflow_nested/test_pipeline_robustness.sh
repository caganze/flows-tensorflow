#!/bin/bash
# Comprehensive Pipeline Robustness Testing
# Tests both brute force and parallel modes for edge cases and failure scenarios

set -e

echo "üß™ PIPELINE ROBUSTNESS TESTING"
echo "============================="
echo "Testing both brute force and parallel execution modes"
echo "Date: $(date)"
echo ""

# Test configuration
TEST_OUTPUT_BASE="/tmp/tfp_flows_robustness_test"
ORIGINAL_H5_FILE=""
MOCK_H5_FILE="$TEST_OUTPUT_BASE/mock_test_data.h5"

# Cleanup function
cleanup() {
    echo "üßπ Cleaning up test files..."
    rm -rf "$TEST_OUTPUT_BASE" 2>/dev/null || true
}
trap cleanup EXIT

# Setup test environment
mkdir -p "$TEST_OUTPUT_BASE"/{trained_flows,samples,logs}

echo "üîç ROBUSTNESS CHECK 1: SLURM Array Bounds and Collision Testing"
echo "================================================================"

# Test 1a: Array indexing edge cases
echo "Testing array indexing logic..."
PARTICLES_PER_JOB=5

test_array_bounds() {
    local test_id="$1"
    local particles_per_job="$2"
    local max_array_id="$3"
    
    echo "  Testing: Array ID $test_id, PPJ $particles_per_job, Max $max_array_id"
    
    START_PID=$(( ($test_id - 1) * $particles_per_job + 1 ))
    END_PID=$(( $test_id * $particles_per_job ))
    
    if [[ $START_PID -le 0 ]]; then
        echo "    ‚ùå ERROR: START_PID=$START_PID (should be > 0)"
        return 1
    fi
    
    if [[ $END_PID -le $START_PID ]]; then
        echo "    ‚ùå ERROR: END_PID=$END_PID <= START_PID=$START_PID"
        return 1
    fi
    
    if [[ $test_id -gt $max_array_id ]]; then
        echo "    ‚ö†Ô∏è  WARNING: Array ID $test_id exceeds max $max_array_id"
        return 2
    fi
    
    echo "    ‚úÖ Valid: PIDs $START_PID-$END_PID"
    return 0
}

# Test edge cases
echo "Edge case testing:"
for test_case in "1,5,200" "200,5,200" "201,5,200" "1,1,1000" "999,1,1000" "1000,1,1000" "1001,1,1000"; do
    IFS=',' read -r array_id ppj max_id <<< "$test_case"
    test_array_bounds "$array_id" "$ppj" "$max_id" || echo "    Failed test case: $test_case"
done

# Test 1b: Brute force indexing
echo ""
echo "Testing brute force indexing logic..."
PIDS=(1 2 3 4 5 23 88 188 268 327)
H5_FILES=("file1.h5" "file2.h5" "file3.h5")

for ARRAY_ID in 1 5 10 15 20 25 30 35; do
    TOTAL_PIDS=${#PIDS[@]}
    FILE_INDEX=$(( (ARRAY_ID - 1) / TOTAL_PIDS ))
    PID_INDEX=$(( (ARRAY_ID - 1) % TOTAL_PIDS ))
    
    echo "  Array ID $ARRAY_ID ‚Üí File[$FILE_INDEX], PID[$PID_INDEX]"
    
    if [[ $FILE_INDEX -ge ${#H5_FILES[@]} ]]; then
        echo "    ‚ö†Ô∏è  File index $FILE_INDEX exceeds available files (${#H5_FILES[@]})"
    elif [[ $PID_INDEX -ge ${#PIDS[@]} ]]; then
        echo "    ‚ùå PID index $PID_INDEX exceeds available PIDs (${#PIDS[@]})"
    else
        echo "    ‚úÖ Valid combination: ${H5_FILES[$FILE_INDEX]}, PID ${PIDS[$PID_INDEX]}"
    fi
done

echo ""
echo "üîí ROBUSTNESS CHECK 2: File Locking and Concurrent Access Safety"
echo "================================================================="

# Test 2a: Concurrent directory creation
echo "Testing concurrent directory creation..."
test_concurrent_dirs() {
    local base_dir="$TEST_OUTPUT_BASE/concurrent_test"
    rm -rf "$base_dir" 2>/dev/null || true
    
    # Simulate multiple jobs creating the same directory structure
    for i in {1..10}; do
        (
            mkdir -p "$base_dir/trained_flows/symphony/halo000"
            mkdir -p "$base_dir/samples/symphony/halo000"
            echo "Job $i completed" > "$base_dir/job_$i.log"
        ) &
    done
    
    wait
    
    if [[ -d "$base_dir/trained_flows/symphony/halo000" && -d "$base_dir/samples/symphony/halo000" ]]; then
        local job_count=$(ls "$base_dir"/job_*.log 2>/dev/null | wc -l)
        echo "  ‚úÖ Concurrent directory creation successful ($job_count jobs completed)"
    else
        echo "  ‚ùå Concurrent directory creation failed"
    fi
}

test_concurrent_dirs

# Test 2b: File writing collision detection
echo ""
echo "Testing concurrent file writing scenarios..."
test_concurrent_writes() {
    local test_dir="$TEST_OUTPUT_BASE/write_test"
    mkdir -p "$test_dir"
    
    # Test writing to the same model file (should be avoided by completion checks)
    echo "  Testing completion check effectiveness..."
    
    local model_file="$test_dir/model_pid1.npz"
    local results_file="$test_dir/model_pid1_results.json"
    
    # Simulate completed job
    echo "fake model data" > "$model_file"
    echo '{"status": "completed"}' > "$results_file"
    
    # Test completion check logic (from submit_flows_array.sh)
    if [[ -f "$model_file" && -f "$results_file" ]]; then
        echo "    ‚úÖ Completion check would skip this PID (avoiding collision)"
    else
        echo "    ‚ùå Completion check failed - collision possible"
    fi
    
    # Test partial completion (only model file exists)
    rm "$results_file"
    if [[ -f "$model_file" && -f "$results_file" ]]; then
        echo "    ‚ùå Would incorrectly skip partial completion"
    else
        echo "    ‚úÖ Would correctly retry incomplete job"
    fi
}

test_concurrent_writes

echo ""
echo "üìä ROBUSTNESS CHECK 3: Memory and Disk Space Validation"
echo "======================================================="

# Test 3a: Disk space checking
echo "Testing disk space requirements..."
check_disk_space() {
    local required_gb="$1"
    local path="$2"
    
    if command -v df >/dev/null 2>&1; then
        local available_kb=$(df "$path" | awk 'NR==2 {print $4}')
        local available_gb=$((available_kb / 1024 / 1024))
        
        echo "  Available space: ${available_gb}GB (required: ${required_gb}GB)"
        
        if [[ $available_gb -ge $required_gb ]]; then
            echo "  ‚úÖ Sufficient disk space"
            return 0
        else
            echo "  ‚ùå Insufficient disk space"
            return 1
        fi
    else
        echo "  ‚ö†Ô∏è  Cannot check disk space (df not available)"
        return 2
    fi
}

# Check current directory space (typical requirements)
check_disk_space 10 "."  # 10GB for moderate training

# Test 3b: Memory estimation
echo ""
echo "Testing memory estimation..."
estimate_memory_usage() {
    local batch_size="$1"
    local n_layers="$2"
    local hidden_units="$3"
    
    # Rough estimation: batch_size * layers * hidden_units * 8 bytes (float64) * overhead
    local base_memory=$(( batch_size * n_layers * hidden_units * 8 * 4 ))  # 4x overhead
    local memory_mb=$(( base_memory / 1024 / 1024 ))
    
    echo "  Estimated memory for batch=$batch_size, layers=$n_layers, units=$hidden_units: ${memory_mb}MB"
    
    if [[ $memory_mb -gt 32000 ]]; then  # 32GB
        echo "    ‚ö†Ô∏è  High memory usage - consider reducing batch size"
    elif [[ $memory_mb -gt 128000 ]]; then  # 128GB
        echo "    ‚ùå Excessive memory usage - job likely to fail"
    else
        echo "    ‚úÖ Memory usage within reasonable bounds"
    fi
}

# Test various configurations
estimate_memory_usage 512 4 64    # Small
estimate_memory_usage 1024 6 128  # Medium
estimate_memory_usage 2048 8 256  # Large

echo ""
echo "üîÑ ROBUSTNESS CHECK 4: Partial Failure Recovery"
echo "==============================================="

# Test 4a: Partial file cleanup
echo "Testing partial failure scenarios..."
test_partial_failure() {
    local test_dir="$TEST_OUTPUT_BASE/failure_test"
    mkdir -p "$test_dir"
    
    # Simulate partial completion scenarios
    echo "  Scenario 1: Model exists, no results file"
    local model1="$test_dir/model_pid1.npz"
    echo "partial model" > "$model1"
    
    if [[ -f "$model1" && ! -f "${model1%.npz}_results.json" ]]; then
        echo "    ‚úÖ Detected incomplete training (model without results)"
    fi
    
    echo "  Scenario 2: Results exist, no model file"
    local results2="$test_dir/model_pid2_results.json"
    echo '{"status": "incomplete"}' > "$results2"
    
    if [[ ! -f "${results2%_results.json}.npz" && -f "$results2" ]]; then
        echo "    ‚úÖ Detected incomplete training (results without model)"
    fi
    
    echo "  Scenario 3: Corrupted files (zero size)"
    local model3="$test_dir/model_pid3.npz"
    local results3="$test_dir/model_pid3_results.json"
    touch "$model3" "$results3"  # Zero-size files
    
    if [[ ! -s "$model3" || ! -s "$results3" ]]; then
        echo "    ‚úÖ Would detect corrupted files (zero size)"
    fi
}

test_partial_failure

echo ""
echo "üåê ROBUSTNESS CHECK 5: Environment Variable Propagation"
echo "======================================================="

# Test 5a: Environment variable handling
echo "Testing environment variable propagation..."
test_env_vars() {
    echo "  Testing OUTPUT_BASE_DIR propagation..."
    
    # Test default behavior
    unset OUTPUT_BASE_DIR
    local default_output="${OUTPUT_BASE_DIR:-/oak/stanford/orgs/kipac/users/caganze/tfp_flows_output}"
    echo "    Default: $default_output"
    
    # Test custom override
    export OUTPUT_BASE_DIR="/custom/path"
    local custom_output="${OUTPUT_BASE_DIR:-/oak/stanford/orgs/kipac/users/caganze/tfp_flows_output}"
    echo "    Custom: $custom_output"
    
    if [[ "$custom_output" == "/custom/path" ]]; then
        echo "    ‚úÖ Environment variable override works"
    else
        echo "    ‚ùå Environment variable override failed"
    fi
    
    unset OUTPUT_BASE_DIR
}

test_env_vars

# Test 5b: SLURM variable availability
echo ""
echo "Testing SLURM variable handling..."
test_slurm_vars() {
    echo "  Testing SLURM_ARRAY_TASK_ID fallback..."
    
    unset SLURM_ARRAY_TASK_ID
    local task_id="${SLURM_ARRAY_TASK_ID:-1}"
    
    if [[ "$task_id" == "1" ]]; then
        echo "    ‚úÖ SLURM_ARRAY_TASK_ID fallback works"
    else
        echo "    ‚ùå SLURM_ARRAY_TASK_ID fallback failed"
    fi
    
    export SLURM_ARRAY_TASK_ID="42"
    local custom_task_id="${SLURM_ARRAY_TASK_ID:-1}"
    
    if [[ "$custom_task_id" == "42" ]]; then
        echo "    ‚úÖ SLURM_ARRAY_TASK_ID propagation works"
    else
        echo "    ‚ùå SLURM_ARRAY_TASK_ID propagation failed"
    fi
    
    unset SLURM_ARRAY_TASK_ID
}

test_slurm_vars

echo ""
echo "‚úÖ ROBUSTNESS CHECK 1-5 COMPLETED"
echo "================================="
echo "Next checks (6-15) would require more extensive infrastructure testing"
echo "including actual file I/O, network simulation, and performance profiling."
echo ""
echo "üìã SUMMARY OF FINDINGS:"
echo "‚Ä¢ Array indexing logic appears robust with bounds checking"
echo "‚Ä¢ Concurrent directory creation is safe (mkdir -p)"
echo "‚Ä¢ Completion checking prevents file collisions"
echo "‚Ä¢ Environment variable fallbacks work correctly"
echo "‚Ä¢ Partial failure detection mechanisms in place"
echo ""
echo "‚ö†Ô∏è  RECOMMENDATIONS:"
echo "‚Ä¢ Add disk space checking before job submission"
echo "‚Ä¢ Consider memory estimation based on batch size"
echo "‚Ä¢ Implement automatic cleanup of corrupted/incomplete files"
echo "‚Ä¢ Add timeout mechanisms for long-running jobs"
